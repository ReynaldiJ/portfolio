{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReynaldiJ/portfolio/blob/main/text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37Pea_Xw-7lN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay5Q2gOYAlME",
        "outputId": "6b6c41bf-4f44-41f0-a1ee-6eeedf08de71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lr3vvml-7lO"
      },
      "outputs": [],
      "source": [
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    #split the sentences based on dot (.) separator\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        #remove non alphabetic character\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop()\n",
        "\n",
        "    return sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xh94hgb-7lO"
      },
      "outputs": [],
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        "\n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        "\n",
        "    all_words = list(set(sent1 + sent2))\n",
        "\n",
        "    #build vector 0 with dimension following the len of all_words\n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        "\n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        "\n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        "\n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aldjfipl-7lP"
      },
      "outputs": [],
      "source": [
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85m1oRxH-7lP"
      },
      "outputs": [],
      "source": [
        "def generate_summary(file_name, top_n):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)\n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarize texr\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JbaBMXI5_imO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "nQlmWr0t-7lP",
        "outputId": "d6fffe7b-905c-4887-a34b-c7d505c26b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jakarta, CNN Indonesia -- Pusat Pimpinan (PP) Muhammadiyah memutuskan untuk mengalihkan dana mereka dari Bank Syariah Indonesia (BSI) ke sejumlah bank lainnya.\n",
            "\n",
            "Indexes of top ranked_sentence order are  []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e70901b6f9e3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"sample1.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-63df0123772c>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(file_name, top_n)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0msummarize_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranked_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Step 5 - Offcourse, output the summarize texr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "generate_summary( \"sample1.txt\", 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2HaLzee-7lQ",
        "outputId": "f566d47a-adff-49df-a21a-69822945729d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If for some reason you wanted to bring it from a pleasant 20C to boiling point, German firm MAN Energy Solutions has a heat pump that could do it\n",
            "And it would take less time than Kenneth Branagh's film version of Hamlet.\"We can do this in less than four hours,\" explains Raymond Decorvet, who works in business development at MAN Energy\n",
            "\"Or we could freeze the whole thing in about 11 hours.\"Theirs is among the largest heat pump units in the world\n",
            "Heat pumps work by compressing gently warmed refrigerants to raise the temperature of these fluids\n",
            "That heat can then be passed on to homes or industrial machinery.Heat pumps require electricity to work but can produce around three or four kilowatts of heat for every kilowatt of power they consume, making them highly efficient\n",
            "Plus, some designs can provide cooling as well.Heat pumps are increasingly popular with some home owners but domestic devices are relatively small and tend to have outputs of several kilowatts or so\n",
            "MAN Energy's biggest commercial heat pump is thousands of times more powerful - with a total heating capacity of 48 megawatts (MW).It can produce temperatures of up to 150C and heat thousands of homes, not just one\n",
            "The company recently installed two of these machines in the port city of Esbjerg, in Denmark.In this installation, the heat pumps' CO2 refrigerant will absorb a small amount of heat from seawater\n",
            "Compressors boost the temperature of the CO2 and the system can then transfer this heat, providing water of up to 90C to a district heating system serving 27,000 households.\n"
          ]
        }
      ],
      "source": [
        "sentences =  read_article(\"sample.txt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKxVM278-7lQ"
      },
      "outputs": [],
      "source": [
        "sentence_similarity_martix = build_similarity_matrix(sentences, stop_words=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYL4cXDN-7lQ",
        "outputId": "8b1f94b3-8954-48fb-b3c0-66dd299947bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.        , 0.13710212, 0.09416472, 0.13093073, 0.19518001,\n",
              "        0.11268723, 0.18574538, 0.12198751],\n",
              "       [0.13710212, 0.        , 0.12049505, 0.04188539, 0.11707323,\n",
              "        0.08111071, 0.15597978, 0.18731716],\n",
              "       [0.09416472, 0.12049505, 0.        , 0.19178532, 0.05360563,\n",
              "        0.        , 0.10202887, 0.4020422 ],\n",
              "       [0.13093073, 0.04188539, 0.19178532, 0.        , 0.2981424 ,\n",
              "        0.12909944, 0.24826442, 0.3354102 ],\n",
              "       [0.19518001, 0.11707323, 0.05360563, 0.2981424 , 0.        ,\n",
              "        0.26461887, 0.33704692, 0.20833333],\n",
              "       [0.11268723, 0.08111071, 0.        , 0.12909944, 0.26461887,\n",
              "        0.        , 0.18314742, 0.09622504],\n",
              "       [0.18574538, 0.15597978, 0.10202887, 0.24826442, 0.33704692,\n",
              "        0.18314742, 0.        , 0.33704692],\n",
              "       [0.12198751, 0.18731716, 0.4020422 , 0.3354102 , 0.20833333,\n",
              "        0.09622504, 0.33704692, 0.        ]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_similarity_martix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBaZz-Lb-7lQ"
      },
      "outputs": [],
      "source": [
        "sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-IBep-a-7lR",
        "outputId": "b6a5f0f3-3a36-4a26-a081-59985d71f378"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x130e00650>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_similarity_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJCXYuto-7lR",
        "outputId": "2fbd71a2-b329-4a36-ea96-6bcb48d87612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyvis\n",
            "  Obtaining dependency information for pyvis from https://files.pythonhosted.org/packages/ab/4b/e37e4e5d5ee1179694917b445768bdbfb084f5a59ecd38089d3413d4c70f/pyvis-0.3.2-py3-none-any.whl.metadata\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from pyvis) (8.12.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from pyvis) (3.1.2)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from pyvis) (3.0.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from pyvis) (3.1)\n",
            "Requirement already satisfied: backcall in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: decorator in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.18.1)\n",
            "Requirement already satisfied: matplotlib-inline in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.36)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=5 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
            "Requirement already satisfied: appnope in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=5.3.0->pyvis) (0.2.5)\n",
            "Requirement already satisfied: executing in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.8.3)\n",
            "Requirement already satisfied: asttokens in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
            "Requirement already satisfied: six in /Users/liliayu/anaconda3/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n",
            "Using cached pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "Installing collected packages: pyvis\n",
            "Successfully installed pyvis-0.3.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vWR-9qA-7lR",
        "outputId": "88fd7530-b416-4291-8602-ffb910a4e004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
            "example.html\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"example.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x1309bfd50>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyvis.network import Network\n",
        "net=Network(notebook=True)\n",
        "net.from_nx(sentence_similarity_graph)\n",
        "net.show('example.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMPJbKJX-7lR"
      },
      "outputs": [],
      "source": [
        "scores = nx.pagerank(sentence_similarity_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PBY4EsN-7lR",
        "outputId": "c5bf8187-959c-4063-effa-e77cafcbf147"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 0.12907083196593166,\n",
              " 1: 0.12907083196593166,\n",
              " 2: 0.11278750410220478,\n",
              " 3: 0.12907083196593166,\n",
              " 4: 0.12907083196593166,\n",
              " 5: 0.11278750410220478,\n",
              " 6: 0.12907083196593166,\n",
              " 7: 0.12907083196593166}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI2L9cki-7lR"
      },
      "outputs": [],
      "source": [
        "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py_YlQRY-7lR",
        "outputId": "b59bd952-3ddb-47f1-9bcd-52fc9fd6f7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indexes of top ranked_sentence order are  [(0.12907083196593166, ['The', 'company', 'recently', 'installed', 'two', 'of', 'these', 'machines', 'in', 'the', 'port', 'city', 'of', 'Esbjerg,', 'in', 'Denmark.In', 'this', 'installation,', 'the', 'heat', \"pumps'\", 'CO2', 'refrigerant', 'will', 'absorb', 'a', 'small', 'amount', 'of', 'heat', 'from', 'seawater']), (0.12907083196593166, ['That', 'heat', 'can', 'then', 'be', 'passed', 'on', 'to', 'homes', 'or', 'industrial', 'machinery.Heat', 'pumps', 'require', 'electricity', 'to', 'work', 'but', 'can', 'produce', 'around', 'three', 'or', 'four', 'kilowatts', 'of', 'heat', 'for', 'every', 'kilowatt', 'of', 'power', 'they', 'consume,', 'making', 'them', 'highly', 'efficient']), (0.12907083196593166, ['MAN', \"Energy's\", 'biggest', 'commercial', 'heat', 'pump', 'is', 'thousands', 'of', 'times', 'more', 'powerful', '-', 'with', 'a', 'total', 'heating', 'capacity', 'of', '48', 'megawatts', '(MW).It', 'can', 'produce', 'temperatures', 'of', 'up', 'to', '150C', 'and', 'heat', 'thousands', 'of', 'homes,', 'not', 'just', 'one']), (0.12907083196593166, ['If', 'for', 'some', 'reason', 'you', 'wanted', 'to', 'bring', 'it', 'from', 'a', 'pleasant', '20C', 'to', 'boiling', 'point,', 'German', 'firm', 'MAN', 'Energy', 'Solutions', 'has', 'a', 'heat', 'pump', 'that', 'could', 'do', 'it']), (0.12907083196593166, ['Heat', 'pumps', 'work', 'by', 'compressing', 'gently', 'warmed', 'refrigerants', 'to', 'raise', 'the', 'temperature', 'of', 'these', 'fluids']), (0.12907083196593166, ['And', 'it', 'would', 'take', 'less', 'time', 'than', 'Kenneth', \"Branagh's\", 'film', 'version', 'of', 'Hamlet.\"We', 'can', 'do', 'this', 'in', 'less', 'than', 'four', 'hours,\"', 'explains', 'Raymond', 'Decorvet,', 'who', 'works', 'in', 'business', 'development', 'at', 'MAN', 'Energy']), (0.11278750410220478, ['Plus,', 'some', 'designs', 'can', 'provide', 'cooling', 'as', 'well.Heat', 'pumps', 'are', 'increasingly', 'popular', 'with', 'some', 'home', 'owners', 'but', 'domestic', 'devices', 'are', 'relatively', 'small', 'and', 'tend', 'to', 'have', 'outputs', 'of', 'several', 'kilowatts', 'or', 'so']), (0.11278750410220478, ['\"Or', 'we', 'could', 'freeze', 'the', 'whole', 'thing', 'in', 'about', '11', 'hours.\"Theirs', 'is', 'among', 'the', 'largest', 'heat', 'pump', 'units', 'in', 'the', 'world'])]\n"
          ]
        }
      ],
      "source": [
        "print(\"Indexes of top ranked_sentence order are \", ranked_sentence)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}